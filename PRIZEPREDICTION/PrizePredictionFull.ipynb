{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import operator\n",
    "from operator import itemgetter\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def encode_cats(df, column):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[column])\n",
    "    df[column] = le.transform(df[column])    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOCATIONS\n",
    "folder   = 'FinalLocationFiles/'\n",
    "df_loc_Q = {}\n",
    "files    = os.listdir(folder)\n",
    "\n",
    "for fn in files:\n",
    "    \n",
    "    field = fn.rsplit('_', 2)[0]\n",
    "    df    = pd.DataFrame.from_csv(folder + fn, sep = '\\t')\n",
    "    df = df.replace('uk' , 'united kingdom')\n",
    "    df = df.replace('south korea' , 'korea')\n",
    "    df = df.replace('hong kong' , 'china')\n",
    "    df = df.replace('czech republic' , 'czech rep.')\n",
    "    df = df.replace('usa' , 'united states')\n",
    "    df_loc_Q[field] = df\n",
    "    \n",
    "    \n",
    "    \n",
    "### GENDER\n",
    "folder      = 'FinalGenderFiles/'\n",
    "df_gender_Q = {}\n",
    "files       = os.listdir(folder)\n",
    "field_avg_Q = []\n",
    "field_std_Q = []\n",
    "field_len_Q = []\n",
    "\n",
    "for fn in files:\n",
    "\n",
    "    field = fn.split('_')[0]\n",
    "    df    = pd.DataFrame.from_csv(folder + fn, sep = '\\t', index_col = 'id')\n",
    "    df    = df[df.gender.isin(['male', 'female'])]\n",
    "    df_gender_Q[field] = df  \n",
    "    \n",
    "  \n",
    "\n",
    "### USERS CAREER TIME\n",
    "folder     = 'UsersTimeData/'\n",
    "files      = os.listdir(folder)\n",
    "career_dfs = {}\n",
    "\n",
    "for fn in files:\n",
    "    \n",
    "    field = fn.split('_')[0]\n",
    "    df    = pd.DataFrame.from_csv(folder + fn, sep = '\\t', header = None)\n",
    "    df.index.name = 'id'\n",
    "    df    = df.rename(columns = { 1 : 'first year', 2 : 'total span', 3 : 'productivity', 4 : 'best'})\n",
    "    career_dfs[field] = df\n",
    "    \n",
    "\n",
    "    \n",
    "# p PARAMS\n",
    "folder     = 'pData/p_stat_data_'\n",
    "files      = [(folder + f + '_0.dat', f ) for f in career_dfs.keys()  ]\n",
    "df_pparams = {}\n",
    "\n",
    "for (fn, field) in files:  \n",
    "    field = field.split('-')[0]\n",
    "    if 'art' in fn: fn = fn.replace('art', 'art_director-20')\n",
    "    if 'art' in field: field = 'art_director'\n",
    "\n",
    "    df = pd.DataFrame.from_csv(fn, sep = '\\t')\n",
    "    df = df.drop(columns = ['Q', 'median_p'])\n",
    "    df_pparams[field] = df\n",
    "    \n",
    "    \n",
    "# MERGING\n",
    "merged_dfs ={}\n",
    "\n",
    "for field, df in career_dfs.items():\n",
    "    \n",
    "    field =  field.rsplit('-', 1)[0]\n",
    "    df_g  = df_gender_Q[field]\n",
    "    \n",
    "    if 'art' in field: field = 'art_director'\n",
    "\n",
    "    df_l     = df_loc_Q[field]\n",
    "    df_feats = df_l.merge(df_g, left_index = True, right_index = True)\n",
    "    df_feats = df_feats.merge(df, left_index = True, right_index = True)\n",
    "    df_feats = df_feats.rename(columns = {'Q_x' : 'Q'})\n",
    "    df_feats = df_feats.drop(columns = ['Q_y'])\n",
    "    df_feats = df_feats.merge(df_pparams[field], left_index = True, right_index = True)\n",
    "\n",
    "    merged_dfs[field] = df_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRIZES\n",
    "\n",
    "books_nobel    = [int(line.strip().split('\\t')[0]) for line in  open('Prize_data/Book/Nobel_winners_all.dat')]\n",
    "books_pulitzer = [int(line.strip().split('\\t')[0]) for line in  open('Prize_data/Book/Pulitzer_winners_all.dat')]\n",
    "film_oscar     = [line.strip().split('\\t')[0] for line in  open('Prize_data/Film/Oscar_winners.dat')]\n",
    "\n",
    "\n",
    "genres             = os.listdir('Prize_data/Music')\n",
    "genre_files_09     = ['Prize_data/Music/' + genre + '/' + genre + '_0.9.dat' for genre in genres]\n",
    "genre_files_095    = ['Prize_data/Music/' + genre + '/' + genre + '_0.95.dat' for genre in genres]\n",
    "music_grammies_09  = list(set([item for sublist in [ [int(line.strip().split('\\t')[1]) for line in open(fn)]  for fn in genre_files_09]   for item in sublist]))\n",
    "music_grammies_095 = list(set([item for sublist in [ [int(line.strip().split('\\t')[1]) for line in open(fn)]  for fn in genre_files_095]  for item in sublist]))\n",
    "professions_prizes = {}\n",
    "\n",
    "\n",
    "professions_prizes    = []\n",
    "professions_prizes.append(('authors', 'books_nobel',    books_nobel))\n",
    "professions_prizes.append(('authors', 'books_pulitzer', books_pulitzer))\n",
    "\n",
    "for prof in ['art_director', 'composer', 'director', 'producer', 'writer']:\n",
    "    professions_prizes.append((prof, 'film_oscar', film_oscar))\n",
    "    \n",
    "for prof in ['rock', 'electro', 'pop', 'funk', 'folk', 'jazz', 'hiphop', 'classical']:\n",
    "    professions_prizes.append((prof, 'music_grammies_09',  music_grammies_09))\n",
    "    professions_prizes.append((prof, 'music_grammies_095', music_grammies_095))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_prizes = {}\n",
    "\n",
    "\n",
    "for (prof, prize, prize_names) in professions_prizes:\n",
    "    \n",
    "    df = merged_dfs[prof]\n",
    "    \n",
    "    prize_names_present = list(set(prize_names).intersection(set(df.index)))      \n",
    "\n",
    "    names_and_prizes = {}\n",
    "    for name in list(df.index):\n",
    "        if name not in prize_names_present:\n",
    "            names_and_prizes[name] = 0\n",
    "        else:\n",
    "            names_and_prizes[name] = 1\n",
    "            \n",
    "    \n",
    "    df_prize = pd.DataFrame(names_and_prizes.items())      \n",
    "    df_prize = df_prize.rename(columns = { 0 : 'id', 1 : 'prizewinner'})\n",
    "    df_prize.index = df_prize.id\n",
    "    df_prize = df_prize.drop(columns = ['id'])  \n",
    "\n",
    "    df = df.merge(df_prize, left_index = True, right_index = True)\n",
    "    features_prizes[prof] = df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 48\n",
      "636 1811\n"
     ]
    }
   ],
   "source": [
    "def get_data_stats(artists_prizes, prize):\n",
    "    \n",
    "    directors_oscars_0 = artists_prizes[artists_prizes[prize] == 0]\n",
    "    directors_oscars_1 = artists_prizes[artists_prizes[prize] == 1]\n",
    "    \n",
    "    countries_winner = Counter(list(directors_oscars_1.location))\n",
    "    countries_loser  = Counter(list(directors_oscars_0.location))\n",
    "\n",
    "    Q_winner = np.mean(list(directors_oscars_1.Q))\n",
    "    Q_loser  = np.mean(list(directors_oscars_0.Q)) \n",
    "    \n",
    "    female_winner = len(directors_oscars_1[directors_oscars_1.gender == 'female'])\n",
    "    male_winner   = len(directors_oscars_1[directors_oscars_1.gender == 'male'])\n",
    "    female_loser  = len(directors_oscars_0[directors_oscars_0.gender == 'female'])\n",
    "    male_loser    = len(directors_oscars_0[directors_oscars_0.gender == 'male'])\n",
    "    \n",
    "    \n",
    "    print female_winner, male_winner\n",
    "    print female_loser,  male_loser\n",
    "    \n",
    "    \n",
    "get_data_stats(features_prizes['authors'], 'prizewinner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_data(artists_prizes, prize, feature = ''):\n",
    "    \n",
    "    if len(feature) > 0:\n",
    "        artists_prizes = artists_prizes.drop(columns= [c for c in artists_prizes.keys() if c not in [feature, 'prizewinner']])\n",
    "    \n",
    "    directors_oscars_0 = artists_prizes[artists_prizes[prize] == 0]\n",
    "    directors_oscars_1 = artists_prizes[artists_prizes[prize] == 1]\n",
    "    directors_oscars_0 = directors_oscars_0.sample(len(directors_oscars_1))\n",
    " \n",
    "    directors_oscars_balanced = directors_oscars_0.append(directors_oscars_1)\n",
    "    directors_oscars_balanced = directors_oscars_balanced.sample(frac = 1)\n",
    "\n",
    "    directors_oscars_balanced.head()\n",
    "\n",
    "    X = directors_oscars_balanced.drop(columns = [prize])\n",
    "    y = np.asarray(directors_oscars_balanced[prize])\n",
    "    \n",
    "    \n",
    "    if 'gender' in X.keys():    encode_cats(X, 'gender')\n",
    "    if 'location' in X.keys():  encode_cats(X, 'location')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature\tbest_acc\terror\tmax_depth\tlearning_rate\tsubsample_size\n",
      "all \t0.77656 \t0.016 \t5\t0.05\t0.5\n",
      "location \t0.63868 \t0.01531 \t5\t0.05\t0.8\n",
      "Q \t0.69175 \t0.01739 \t5\t0.05\t0.8\n",
      "gender \t0.50196 \t0.00767 \t5\t0.01\t0.8\n",
      "first year \t0.56262 \t0.01718 \t5\t0.01\t0.5\n",
      "total span \t0.5526 \t0.01723 \t4\t0.05\t0.8\n",
      "productivity \t0.49036 \t0.02042 \t4\t0.05\t0.5\n",
      "best \t0.6714 \t0.01677 \t4\t0.01\t0.8\n",
      "mean_p \t0.64461 \t0.01733 \t5\t0.01\t0.5\n"
     ]
    }
   ],
   "source": [
    "def xgb_model_params_importance(X, y, max_depth_, learning_rate_, subsample_, n_thread_):\n",
    "    \n",
    "    train_data, test_data, train_label, test_label =  train_test_split(X, y, test_size=.33, random_state=42, stratify = y)    \n",
    "           \n",
    "    model2       = xgb.XGBClassifier(n_estimators=100, n_thread = n_thread_, max_depth=max_depth_, learning_rate=learning_rate_, subsample=subsample_)\n",
    "    train_model2 = model2.fit(train_data, train_label)\n",
    "    pred2        = train_model2.predict(test_data)\n",
    "    accuracies   = list(cross_val_score(model2, train_data, train_label, cv=10))\n",
    "        \n",
    "    return accuracies\n",
    "\n",
    "\n",
    "R = 5\n",
    "\n",
    "features = ['', 'location', 'Q', 'gender', 'first year', 'total span', 'productivity', 'best', 'mean_p']\n",
    "results  = {}\n",
    "\n",
    "print 'feature\\tbest_acc\\terror\\tmax_depth\\tlearning_rate\\tsubsample_size'\n",
    "\n",
    "\n",
    "for feature in features:\n",
    "\n",
    "\n",
    "    for max_depth_ in [4,5]:\n",
    "        for learningrate_ in [0.01, 0.05]:\n",
    "            for subsample_ in [0.5, 0.8]:\n",
    "\n",
    "                accuracies = []\n",
    "\n",
    "                for i in range(R):\n",
    "                                \n",
    "                    X, y = get_sample_data(features_prizes['director'], 'prizewinner', feature)\n",
    "                    accuracies += xgb_model_params_importance(X, y, max_depth_, learning_rate_, subsample_, 1)\n",
    "    \n",
    "                params =  str(max_depth_) + '_' + str(learningrate_) + '_' +  str(subsample_)\n",
    "                results[params] = (np.mean(accuracies), np.std(accuracies) / math.sqrt(len(accuracies)))\n",
    "\n",
    "\n",
    "                \n",
    "    best_pred   = max(results.values(), key = itemgetter(1))\n",
    "    best_acc    = best_pred[0]\n",
    "    best_error  = best_pred[1]\n",
    "    best_params = [k for k, v in results.items() if best_acc == v[0]][0].replace('_', '\\t')\n",
    "    if feature == '': feature = 'all'\n",
    "\n",
    "    print feature, '\\t', round(best_acc,5), '\\t', round(best_error, 5) ,'\\t' + best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- GRIDSEARCH\n",
    "- RANDOM SAMPLING N param\n",
    "- MULTITHREAD xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "\n",
    "- nthread!\n",
    "- save avg params within sample groups\n",
    "- param scanning on learning rate, depth, subsample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
